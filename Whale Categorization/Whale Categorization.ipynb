{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.image as mpimage\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "folder = \"D:\\ProgrammingBigFiles\\Kaggle\\Whale Categorization\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading database\n",
    "\n",
    "idDict = {}\n",
    "train = pd.read_csv(folder + \"train.csv\")\n",
    "for i in train.iterrows():\n",
    "    if not train.loc[i[0]][1] in idDict:\n",
    "        idDict[train.loc[i[0]][1]] = len(idDict)\n",
    "    train.loc[i[0]][0] = folder + \"train\\\\\" + train.loc[i[0]][0]\n",
    "    train.loc[i[0]][1] = idDict[train.loc[i[0]][1]]\n",
    "test = np.array(os.listdir(folder + \"test\"))\n",
    "for i in range(len(test)):\n",
    "    test[i] = folder + \"test\\\\\" + test[i]\n",
    "    \n",
    "x_train, y_train = train.iloc[:, 0], train.iloc[:, 1]\n",
    "\n",
    "width, height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 22:59:07.033000 14864 deprecation.py:323] From C:\\Users\\Nelson Gomes Neto\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "0.0101523%\n",
      "0.0203046%\n",
      "0.0304569%\n",
      "0.0406091%\n",
      "0.0507614%\n",
      "0.0609137%\n",
      "0.071066%\n",
      "0.0812183%\n",
      "0.0913706%\n",
      "0.101523%\n",
      "0.111675%\n",
      "0.121827%\n",
      "0.13198%\n",
      "0.142132%\n",
      "0.152284%\n",
      "0.162437%\n",
      "0.172589%\n",
      "0.182741%\n",
      "0.192893%\n",
      "0.203046%\n",
      "0.213198%\n",
      "0.22335%\n",
      "0.233503%\n",
      "0.243655%\n",
      "0.253807%\n",
      "0.263959%\n",
      "0.274112%\n",
      "0.284264%\n",
      "0.294416%\n",
      "0.304569%\n",
      "0.314721%\n",
      "0.324873%\n",
      "0.335025%\n",
      "0.345178%\n",
      "0.35533%\n",
      "0.365482%\n",
      "0.375635%\n",
      "0.385787%\n",
      "0.395939%\n",
      "0.406091%\n",
      "0.416244%\n",
      "0.426396%\n",
      "0.436548%\n",
      "0.446701%\n",
      "0.456853%\n",
      "0.467005%\n",
      "0.477157%\n",
      "0.48731%\n",
      "0.497462%\n",
      "0.507614%\n",
      "0.517766%\n",
      "0.527919%\n",
      "0.538071%\n",
      "0.548223%\n",
      "0.558376%\n",
      "0.568528%\n",
      "0.57868%\n",
      "0.588832%\n",
      "0.598985%\n",
      "0.609137%\n",
      "0.619289%\n",
      "0.629442%\n",
      "0.639594%\n",
      "0.649746%\n",
      "0.659898%\n",
      "0.670051%\n",
      "0.680203%\n",
      "0.690355%\n",
      "0.700508%\n",
      "0.71066%\n",
      "0.720812%\n",
      "0.730964%\n",
      "0.741117%\n",
      "0.751269%\n",
      "0.761421%\n",
      "0.771574%\n",
      "0.781726%\n",
      "0.791878%\n",
      "0.80203%\n",
      "0.812183%\n",
      "0.822335%\n",
      "0.832487%\n",
      "0.84264%\n",
      "0.852792%\n",
      "0.862944%\n",
      "0.873096%\n",
      "0.883249%\n",
      "0.893401%\n",
      "0.903553%\n",
      "0.913706%\n",
      "0.923858%\n",
      "0.93401%\n",
      "0.944162%\n",
      "0.954315%\n",
      "0.964467%\n",
      "0.974619%\n",
      "0.984772%\n",
      "0.994924%\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(150, 150, 3)),\n",
    "        tf.keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(4251, activation=tf.nn.softmax)\n",
    "    ])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_crossentropy', 'accuracy'])\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    image = tf.keras.preprocessing.image.load_img(x_train[i], target_size=(width, height))\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    x = np.array([image])\n",
    "    y = np.array([np.zeros(4251)])\n",
    "    y[0][y_train[i]] = 1\n",
    "    model.fit(x, y, epochs=1, verbose=False)\n",
    "    if i % 100 == 0:\n",
    "        print(\"%Lg%%\" % (i / len(x_train)))\n",
    "# model.evaluate(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2949, array([30]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = tf.keras.preprocessing.image.load_img(x_train[616], target_size=(width, height))\n",
    "image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "x, y = np.array([image]), np.array([y_train[616]])\n",
    "np.argmax(model.predict(x)), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning model\n",
    "\n",
    "model = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(width, height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting features\n",
    "\n",
    "features = []\n",
    "for line in train.iterrows():\n",
    "    image = tf.keras.preprocessing.image.load_img(line[1][0], target_size=(width, height))\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    feature = model.predict(image)\n",
    "    features += [feature]\n",
    "    if len(features) % 100 == 0:\n",
    "        print(\"%Lg%%\" % (len(features) / len(train)))\n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming output\n",
    "\n",
    "targets = LabelEncoder().fit_transform(labels)\n",
    "lr = LogisticRegression(solver=\"lbfgs\")\n",
    "lr.fit(features, targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "5241e48e-9232-4c28-887c-ab19aa0f6282"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
